Subcommand: load
================

Purpose: Inspect existing CaseSet assets (read-only).

Use this when you need to understand extracted features, verify trigger
coverage, check case counts, or debug feature quality issues.

---

What To Read
============

CaseSets live under `_WorkSpace/3-CaseStore/`. CaseFn parquet files are
**@-prefixed and at the ROOT level** of the CaseSet directory.

```
_WorkSpace/3-CaseStore/
+-- OhioT1DM_v0RecSet/
    +-- @v0CaseSet-CGM5MinLTS-Ohio/
        +-- df_case.parquet              Main case table (PID, ObsDT, trigger cols)
        +-- df_lts.parquet               LTS segments (optional, for LTS triggers)
        +-- df_Human_Info.parquet        Patient metadata (optional)
        +-- @CGMValueBf24h.parquet       CaseFn features (at ROOT, NOT in subdirectory)
        +-- @CGMValueAf24h.parquet       Another CaseFn (at ROOT)
        +-- @DEMEventBf24h.parquet       Another CaseFn (at ROOT)
        +-- @DEMEventAf24h.parquet       Another CaseFn (at ROOT)
        +-- @PDemoBase.parquet           Another CaseFn (at ROOT)
        +-- cf_to_cfvocab.json           Vocabulary per CaseFn
        +-- manifest.json
```

**CRITICAL:**

- The main file is `df_case.parquet`, NOT `case_data.parquet`.
- CaseFn files are `@{CaseFnName}.parquet` at the ROOT level, NOT in a CaseFn/ subdirectory.
- Directory naming: `{RecSetName}/@v{N}CaseSet-{TriggerFolder}/`

---

Load API
========

```python
from haipipe.case_base import CaseSet

# Load existing CaseSet -- full path + SPACE
case_set = CaseSet.load_from_disk(
    path='/full/path/to/3-CaseStore/OhioT1DM_v0RecSet/@v0CaseSet-CGM5MinLTS-Ohio',
    SPACE=SPACE
)

# Load with selective CaseFn loading (faster, less memory)
case_set = CaseSet.load_from_disk(
    path='/full/path/to/3-CaseStore/OhioT1DM_v0RecSet/@v0CaseSet-CGM5MinLTS-Ohio',
    SPACE=SPACE,
    CaseFn_list=['CGMValueBf24h']         # Only load this CaseFn
)

# Alternative: load_asset also works
case_set = CaseSet.load_asset(
    path='/full/path/to/3-CaseStore/OhioT1DM_v0RecSet/@v0CaseSet-CGM5MinLTS-Ohio',
    SPACE=SPACE
)
```

---

Inspect CaseSet Contents
========================

```python
# Base case data (df_case.parquet)
print('Number of cases:', len(case_set.df_case))
print('Case columns:', list(case_set.df_case.columns))
print('Case ID columns: PID, lts_id, ObsDT')

# Per-CaseFn feature parquets (@CaseFnName.parquet)
for cf_name, cf_df in case_set.CaseFn_to_df.items():
    print(f'{cf_name}: {cf_df.shape[0]} rows, {cf_df.shape[1]} cols')
    print(f'  Columns: {list(cf_df.columns)[:10]}...')
    print()

# Check vocabulary
import json
with open(caseset_path + '/cf_to_cfvocab.json') as f:
    cf_vocabs = json.load(f)
for cf_name, vocab in cf_vocabs.items():
    print(f'{cf_name}: {len(vocab.get("tid2tkn", []))} tokens')
```

---

Quick Inspection Commands
=========================

```bash
# List available CaseSets
ls _WorkSpace/3-CaseStore/

# List trigger versions for a RecordSet
ls _WorkSpace/3-CaseStore/OhioT1DM_v0RecSet/

# List all files in a CaseSet (note: @-prefixed CaseFn files at root)
ls _WorkSpace/3-CaseStore/OhioT1DM_v0RecSet/@v0CaseSet-CGM5MinLTS-Ohio/

# Check file sizes
du -sh _WorkSpace/3-CaseStore/OhioT1DM_v0RecSet/@v0CaseSet-CGM5MinLTS-Ohio/*

# Read manifest
cat _WorkSpace/3-CaseStore/OhioT1DM_v0RecSet/@v0CaseSet-CGM5MinLTS-Ohio/manifest.json
```

---

Inspection Checklist
====================

1. **Case count**: Total number of cases generated by trigger (rows in df_case.parquet)
2. **Case ID columns**: Verify PID, lts_id, ObsDT are present in df_case
3. **CaseFn coverage**: Each @CaseFn.parquet should have same number of rows as df_case
4. **Feature columns**: Check each CaseFn output has expected suffix columns (--tid, --wgt, --val, --str)
5. **Feature naming**: Verify `<Feature><Window>` convention (e.g., CGMValueBf24h)
6. **Temporal coverage**: Check ObsDT spans expected date range
7. **Split columns**: If patient_info_path was provided, check split_timebin exists in df_case
8. **Missing data**: Check for NaN/null ratios in feature columns
9. **Manifest**: Check manifest.json for lineage back to RecordSet
10. **Vocabulary**: Check cf_to_cfvocab.json for token counts per CaseFn

---

MUST NOT
========

- **NEVER modify** loaded data or any files in _WorkSpace/3-CaseStore/
- **NEVER assume** data exists -- check first with ls or try/except
- **NEVER load** without activating .venv and sourcing env.sh
- **NEVER look** for CaseFn files in a CaseFn/ subdirectory -- they are at ROOT with @ prefix
- **NEVER look** for case_data.parquet -- the file is df_case.parquet
